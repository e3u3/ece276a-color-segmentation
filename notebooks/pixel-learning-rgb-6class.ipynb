{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "sys.path.insert(0, '../src')\n",
    "import classifier\n",
    "import detector\n",
    "from image import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- done ------\n"
     ]
    }
   ],
   "source": [
    "from image import build_histogram_equalizer\n",
    "TRAIN_DATA_DIR = os.path.abspath(\"../trainset\")\n",
    "COLORS = ['COLOR_STOP_SIGN_RED', 'COLOR_OTHER_RED',\n",
    "          'COLOR_BROWN' , 'COLOR_ORANGE' ,\n",
    "          'COLOR_BLUE' , 'COLOR_OTHER' ]\n",
    "\n",
    "data = {c: [] for c in COLORS}\n",
    "files = os.listdir(TRAIN_DATA_DIR)\n",
    "for fname in files:\n",
    "    name, ext = os.path.splitext(fname)\n",
    "    if ext == \".npz\":\n",
    "        if name + '.jpg' in files:\n",
    "            img = Image.load(os.path.join(TRAIN_DATA_DIR, name) + '.jpg')\n",
    "        elif name + '.png' in files:\n",
    "            img = Image.load(os.path.join(TRAIN_DATA_DIR, name) + '.png')\n",
    "        \n",
    "        npzfname = os.path.join(TRAIN_DATA_DIR, fname)\n",
    "        npzdata = np.load(npzfname)\n",
    "        for c in COLORS:\n",
    "            if npzdata[c].size > 0:\n",
    "                mat = npzdata[c]\n",
    "                mat = mat.reshape(-1, 3).astype(np.uint8)\n",
    "                data[c].append(mat)\n",
    "                \n",
    "for c in COLORS:\n",
    "    data[c] = np.vstack(data[c])\n",
    "\n",
    "print('---- done ------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLOR_STOP_SIGN_RED (1952535, 3)\n",
      "COLOR_OTHER_RED (2234268, 3)\n",
      "COLOR_BROWN (11148031, 3)\n",
      "COLOR_ORANGE (267664, 3)\n",
      "COLOR_BLUE (46662704, 3)\n",
      "COLOR_OTHER (186000767, 3)\n",
      "-----------done------------\n"
     ]
    }
   ],
   "source": [
    "N_DATA_PER_CLASS = 200000\n",
    "APPEND_YCRCB = False\n",
    "APPEND_BIAS = False\n",
    "ONLY_YCRCB = False\n",
    "\n",
    "labelmp = {\n",
    "    'COLOR_STOP_SIGN_RED': 0,\n",
    "    'COLOR_OTHER_RED': 1,\n",
    "    'COLOR_ORANGE': 2,\n",
    "    'COLOR_BROWN': 3,\n",
    "    'COLOR_BLUE': 4,\n",
    "    'COLOR_OTHER': 5\n",
    "}\n",
    "X, y = [], []\n",
    "for ci, c in enumerate(COLORS):\n",
    "    print(c, data[c].shape)\n",
    "    \n",
    "    rndidx = np.random.choice(data[c].shape[0], N_DATA_PER_CLASS, replace=False)\n",
    "    x = data[c][rndidx, :]\n",
    "    \n",
    "    if ONLY_YCRCB:\n",
    "        xycc = cv2.cvtColor(x.reshape(-1, 1, 3).astype(np.uint8), cv2.COLOR_RGB2YCrCb)\n",
    "        xycc = xycc.reshape(-1, 3)\n",
    "        x = xycc\n",
    "    elif APPEND_YCRCB:\n",
    "        xycc = cv2.cvtColor(x.reshape(-1, 1, 3).astype(np.uint8), cv2.COLOR_RGB2YCrCb)\n",
    "        xycc = xycc.reshape(-1, 3)\n",
    "        x = np.hstack([x, xycc])\n",
    "        \n",
    "    if APPEND_BIAS:\n",
    "        x = np.hstack([x, np.ones((N_DATA_PER_CLASS, 1))])\n",
    "        \n",
    "    X.append(x)\n",
    "    y.append(np.ones((N_DATA_PER_CLASS, 1)) * labelmp[c])\n",
    "    \n",
    "X = np.vstack(X).astype(np.float64)\n",
    "y = np.vstack(y).astype(np.int32).reshape(-1)\n",
    "print('-----------done------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssred_accuracy(clf, X, y):\n",
    "    pred = clf.predict(X)\n",
    "    pred = pred == 0\n",
    "    y = y == 0\n",
    "    return np.sum(pred == y) / y.shape[0]\n",
    "\n",
    "def ssred_precision(clf, X, y):\n",
    "    pred = clf.predict(X)\n",
    "    pred = pred == 0\n",
    "    y = y == 0\n",
    "    return np.sum(pred[pred == y]) / np.sum(pred)\n",
    "\n",
    "def ssred_recall(clf, X, y):\n",
    "    pred = clf.predict(X)\n",
    "    pred = pred == 0\n",
    "    y = y == 0\n",
    "    return np.sum(pred[pred == y]) / np.sum(y)\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': ssred_accuracy,\n",
    "    'precision': ssred_precision,\n",
    "    'recall': ssred_recall\n",
    "}\n",
    "\n",
    "def print_scores(scores):\n",
    "    for key, val in scores.items():\n",
    "        print(f'\\t{key}: %0.2f (+/- %0.2f)' % (val.mean(), val.std() * 2))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reload_ext autoreload\n",
    "# from sklearn.model_selection import cross_validate\n",
    "# from sklearn.utils import shuffle\n",
    "# from classifier import LogisticRegression\n",
    "\n",
    "# X, y = shuffle(X, y)\n",
    "# XX = np.hstack([X, np.ones((X.shape[0], 1))])\n",
    "# clf = LogisticRegression(max_iter=200, learning_rate=0.01, batchsize=3000)\n",
    "\n",
    "# lr_score = cross_validate(clf, XX, y, cv=5, n_jobs=-1, scoring=scoring, error_score='raise')\n",
    "# print('Logistic Regression')\n",
    "# print_scores(lr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1vall Logistic Regression\n",
      "\tfit_time: 795.71 (+/- 11.11)\n",
      "\tscore_time: 0.09 (+/- 0.01)\n",
      "\ttest_accuracy: 0.95 (+/- 0.07)\n",
      "\ttest_precision: 0.83 (+/- 0.24)\n",
      "\ttest_recall: 0.94 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.utils import shuffle\n",
    "from classifier import OneVsAllLogisticRegression\n",
    "\n",
    "X, y = shuffle(X, y)\n",
    "XX = np.hstack([X, np.ones((X.shape[0], 1))])\n",
    "\n",
    "clf = OneVsAllLogisticRegression(max_iter=500, learning_rate=0.005, batchsize=3000)\n",
    "\n",
    "ovalr_score = cross_validate(clf, XX, y, cv=5, n_jobs=-1, scoring=scoring, error_score='raise')\n",
    "print('1vall Logistic Regression')\n",
    "print_scores(ovalr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kary Logistic Regression\n",
      "\tfit_time: 192.42 (+/- 2.61)\n",
      "\tscore_time: 0.02 (+/- 0.00)\n",
      "\ttest_accuracy: 0.97 (+/- 0.02)\n",
      "\ttest_precision: 0.95 (+/- 0.04)\n",
      "\ttest_recall: 0.86 (+/- 0.16)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.utils import shuffle\n",
    "from classifier import KaryLogisticRegression\n",
    "\n",
    "X, y = shuffle(X, y)\n",
    "XX = np.hstack([X, np.ones((X.shape[0], 1))])\n",
    "clf = KaryLogisticRegression(max_iter=500, learning_rate=0.005, batchsize=3000)\n",
    "\n",
    "klr_score = cross_validate(clf, XX, y, cv=5, n_jobs=-1, scoring=scoring, error_score='raise')\n",
    "print('Kary Logistic Regression')\n",
    "print_scores(klr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes\n",
      "\tfit_time: 0.22 (+/- 0.01)\n",
      "\tscore_time: 0.27 (+/- 0.00)\n",
      "\ttest_accuracy: 0.98 (+/- 0.00)\n",
      "\ttest_precision: 0.94 (+/- 0.00)\n",
      "\ttest_recall: 0.93 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "from classifier import GaussianNaiveBayes\n",
    "\n",
    "X, y = shuffle(X, y)\n",
    "XX = X\n",
    "clf = classifier.GaussianNaiveBayes()\n",
    "\n",
    "gnb_score = cross_validate(clf, XX, y, cv=5, n_jobs=-1, scoring=scoring, error_score='raise')\n",
    "print('Gaussian Naive Bayes')\n",
    "print_scores(gnb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = shuffle(X, y, random_state=1)\n",
    "# clf = classifier.GaussianNaiveBayes()\n",
    "# clf.fit(X, y)\n",
    "# clf.save('../model/gnb_300000_histeq.pic')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
